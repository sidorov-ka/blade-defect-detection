training:
  num_epochs: 10
  learning_rate: 0.0001
  weight_decay: 0.00001

optimizer:
  name: adam
  lr: ${training.learning_rate}
  weight_decay: ${training.weight_decay}

